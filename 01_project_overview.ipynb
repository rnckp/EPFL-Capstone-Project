{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPFL Extension School Applied Data Science: Machine Learning \n",
    "**Capstone project proposal and overview**\n",
    "<br>Patrick Arnecke, June 2021\n",
    "# Assessing the share of male and female voices in (Swiss-) German audio media with machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1) The problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass media is dominated by male protagonists and voices\n",
    "\n",
    "In many articles, broadcasts, programmes, shows and podcasts audiences will see and hear (and read from and about) way more men than women. \n",
    "\n",
    "[According to the Global Media Monitoring Project 2016, as much as 82% of all media reports are about men](https://www.ringier.com/en/equalvoice-initiative-increase-womens-visibility-media-coverage). In Switzerland this figure is as high as 75%. A [very thorough analysis from INA](https://www.viewjournal.eu/article/10.18146/2213-0969.2018.jethc156/) of about 700k hours of French audiovisual documents in 2018 shows that ***«men speak twice as much as women on TV and on radio.»*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Media equality projects\n",
    "\n",
    "To overcome this inequality media companies have started initiatives to improve the gender balance in their offerings. The most prominent example is BBC's [«50:50 – The equality project»](https://www.bbc.co.uk/5050/). At the time of writing the BBC's project website [lists almost 100 partners that have accepted the 50:50 goal](https://www.bbc.co.uk/5050/partners/home#current5050partners) as a challenge. In Switzerland the SRG SSR has committed to the initiative in form of [«chance50:50»](https://www.srgd.ch/de/aktuelles/news/2021/04/21/srf-steigert-sicht-und-horbarkeit-von-expertinnen-und-gesprachspartnerinnen/). Ringier started their [EqualVoice](https://www.equalvoice.ch/en/) project in 2019.\n",
    "\n",
    "![](https://ichef.bbci.co.uk/images/ic/1920xn/p092wxyl.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking gender ratios in media is time consuming\n",
    "To achieve fairer gender ratios media companies have to actively track gender (im)balance and level out the contribution and presence of men and women. For that the companies have to count the share of female and male contributions in its various forms. Teams can then use this data to inform editorial and production decisions and by that improve gender equality. [The tracking is mostly done manually which is likely quite time consuming. Semiautomatic and automatic methods are employed as well](https://www.reflectreality.internews.org/chapter-4/tracking)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping approach: Automate tracking as much as possible\n",
    "\n",
    "I´d like to **make the tracking of gender in media easier by using audio analysis and machine learning**.\n",
    ">I aim to **build a classifier that identifies the biological sex of a German/Swissgerman speaker in a given audio file.** \n",
    "\n",
    "In my project I want to focus on audio only content like podcast and radio broadcasts that are available online. Though videos and TV programmes will include audio that I could assess and classify, a meaningful analysis of audio*visual* content is even more complex than for audio. There might be voice(s) on and off screen (e.g. a narrator not visible), protagonists on screen might visually contribute to one or the other gender class while not being audible etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical parity is not equality\n",
    "\n",
    "> It is important to acknowledge that **numercial *parity* doesn't imply gender *equality* at all**. \n",
    "\n",
    "- The authors of the INA study call **speaking time percentage per gender *«a surface equality descriptor, which is not sufficient to fully describe gender representations in media.»***\n",
    "- Even with a perfectly balanced 50:50 voice share there can be substantial imbalances in the power structure of the dialogue or the roles the participants have in the interaction (host, expert, side guest or off voice for advertising?) as well as numerous clicheed narratives and stereotypes that might be detrimental to a fair and diverse representation of women and men alike. \n",
    "\n",
    "At the risk of stating the obvious: **True gender parity in media content is a much more facetted and nuanced problem that no amount of technology can fix by itself or even perfectly assess**. \n",
    "\n",
    "**The audio classifier that I aim to build is meant as a helper tool to get a quantitative baseline of voice share more easily than counting manually.** It hopefully will make it less time consuming for media producers to discover gender gaps in media data and encourage improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in regard to terminology: The term «gender» in this project always refers to the *biological sex* of a speaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2) Fundamentals: How do humans recognize a speaker's gender?\n",
    "\n",
    "Differences between the speech of women and men come partly from physiological differences in the vocal organs. Gender perception is based on several auditory clues.\n",
    "\n",
    "- The **fundamental frequency FO** is the measure of the vibratory rate of the vocal folds. The **average FO during conversation for males ranges from 85 to 180 Hz**, whereas **for females it ranges from 165 to 255 Hz**. \n",
    "- The F0-range is influenced by various factors such as language, type of text, type of discourse, and the emotional state of the speaker. \n",
    "- Gender recognition is harder for speakers having marked accents (regional, foreign), extreme pitch ranges, or speaking using non-standard intonation (very expressive voice, imitation, mental disorder etc.).\n",
    "- Perceptual differences are also related to the construction of gender identity in a given socio-cultural context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3) The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available data sets\n",
    "\n",
    "There are **several data sets available in which the gender of the speaker is labeled**. \n",
    "\n",
    "Some of the data sets contain German samples, most of them are **English only**. In speech research gender recognition is considered as influenced by language. However, from first tests I observed that **gender classification seems somewhat agnostic to the language being trained on**. E.g. I can train a model on German samples and predict on French, Italian and Romansh audio samples with just a little less accuracy. \n",
    "\n",
    "Nonetheless it seems **sensible to concentrate on the target languages and put together a suitable German/Swissgerman data set for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available data:\n",
    "\n",
    "**[Mozilla CommonVoice](https://commonvoice.mozilla.org/en/datasets)**\n",
    "- Crowdsourced and freely available data set with more than 9'000 recorded hours (7k+ validated) in 60 languages. **German, French, Italian and Romansh available.** Short utterances between mostly 4 and 14 words. Metadata includes age, sex, accent.\n",
    "- I already have downloaded this data set and have used it for the EDA.\n",
    "\n",
    "In addition to that I make use of training samples in **Swissgerman** from Swiss podcasts that I scraped the podcast RSS feeds. \n",
    "\n",
    "Other data sources that I looked into but haven't used:\n",
    "\n",
    "**[Spoken Wikipedia](https://corpora.uni-hamburg.de/hzsk/de/islandora/object/spoken-corpus:swc-2.0#corpus-description)**\n",
    "- Several hundred Wikipedia articles that are read by users. \n",
    "\n",
    "**[Forvo](https://forvo.com/)**\n",
    "- A website that has gathered millions of pronounciations in many languages. They have an API and offer several data plans. E.g. a small plan that allows the download of 300k samples per month for 30 CHF.\n",
    "\n",
    "[**paperswithcode**](https://paperswithcode.com/datasets?mod=audio&page=1) lists more audio data sets that might come in handy to augment the training data. For example I can take clean speech samples from CommonVoice and add noise, sounds, music from other data sets to create new samples. \n",
    "\n",
    "This [Medium article lists a lot more audio data sets](https://towardsdatascience.com/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad).\n",
    "\n",
    "#### What data do I want to analyze with the trained model?\n",
    "\n",
    "- I want to **analyze the gender ratio in Swiss podcast episodes** e.g. the Top 100 CH on Apple iTunes. I have to scrape these episodes full length via their RSS feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing and processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download audio data sets locally\n",
    "- Scrape a fixed number of episodes of top podcast episodes regarding to iTunes charts Switzerland\n",
    "- Preprocess audio with [pydub](https://github.com/jiaaro/pydub): Set consistent sample rate, normalize, remove silence at beginning and end, etc.\n",
    "- Extract features with [librosa](https://librosa.org/): Mel-frequency cepstral coefficients (MFCCs) are considered as very suitable features to represent audio/speech for machine learning. My first preliminary tests confirm that these are fast to compute and yield good results.\n",
    "- Use [aubio](https://github.com/aubio/aubio) for feature extraction of the fundamental frequency FO.\n",
    "- If needed, create synthetic samples with [Audacity](https://www.audacityteam.org/) and/or [ffmpeg](https://www.ffmpeg.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4) Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations about the **metadata**:\n",
    "\n",
    "- **The data set is strongly biased towards male voices!** Just around 12% of the files are spoken by women.\n",
    "- I find a total of around **3'200 unique male voices versus around 500 unique female voices** in the data set.\n",
    "- **Some people have contributed amazingly large amounts of samples.** The top contributor has recorded almost 39k texts! To avoid a bias towards just a few voices I need to balance out the data to retrieve a sufficiently varied selection.\n",
    "- **Most of the samples have been recorded by people in the age range between 20 and 60**. Since gender in voice is accurately only distinguishable after puberty and not many teens likely will be featured in the mayority of podcasts I decided to remove all teens from the data set.\n",
    "- There is a variety of accents in the data, which I assume will be helpful. However, by far the most samples were recorded by people labeled as Germans (followed by Austrians). \n",
    "- **After initial cleaning and filtering and balancing out gender I have around 35k samples left in the examined German data set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations about the **extracted audio features**:\n",
    "\n",
    "- **Fundamental frequence FO, Short-time Fourier transform (SFTF) and Mel-frequency cepstral coefficients (MFCCs) are correlated to the target variable `gender`**\n",
    "- SFTFs seem less suitable as predicting features (less correlation, possibly colinear to MFCC).\n",
    "- It makes sense to **use statistics (like mean, median, std) of the MFCCs (or time based features in general) rather than using e.g. an MFCC as a whole.** I aim for a **representation of the voice characteristic regardless of the length of the sample and the particular words that were spoken**. Therefore I want to get variations in time and length out of the equation (at least for training non-sequential models). The first model trainings confirm this assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from the **first model trainings with an untuned Logistic regressor**:\n",
    "\n",
    "- **FO and MFCCs work well as predicting features.**\n",
    "- **Training on all available German samples yields an accuracy of 0.96.**\n",
    "- **Outlier removal does not seem to improve accuracy.**\n",
    "- In my first experiments SFTFs degradeded the models quality.\n",
    "- **Prediction works across the examined languages.** A model trained on German can predict French, Italian and Romansh samples with just some percent of loss in accuracy.\n",
    "- Gender can be predicted unsupervised with KMeans with high accuracy (0.9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5) Machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to **train a machine learning model that can distinguish the gender of speaker(s) in German / Swissgerman podcast audio files**. \n",
    "\n",
    "Podcasts often contain music and sound effects e.g. for advertising and opening / closing / transitional segments. I therefore need a second model that distinguishes between speech and music/sounds/noise. Another option is to make the model robust enough to predict gender in speech that is mixed with music and sounds.\n",
    "\n",
    "Criteria for appropiate classifiers:\n",
    "\n",
    "- **Fast inference** – for high volume, low cost. Make near realtime processing or analysis of streaming audio feasible.\n",
    "- **High accuracy** – I want to assess the gender ratio in podcasts as accurately as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suitable models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First experiments during EDA indicate that the extracted features are linearly separable. Suitable models therefore are:\n",
    "\n",
    "- I will train and tune **linear models** (e.g. Logistic regression, GaussianNB). \n",
    "- I will use **non-linear models** e.g. k-NN, RandomForest, SVMs and DNNs to see if these yield better results.\n",
    "- In addition to that I will evaluate **ensemble methods like stacking and voting classifiers**. \n",
    "\n",
    "Overview of advantages/disadvantages:\n",
    "\n",
    "**Logistic Regression**\n",
    "- ✅ Likely good as a baseline\n",
    "- 🤔 Can't solve non-linear problems\n",
    "\n",
    "**Quadratic Discriminant Analysis**\n",
    "- ✅ Easy and fast to compute\n",
    "- ✅ Inherently multiclass, e.g. could be trained to predict music as well\n",
    "- ✅ Known to «work well in practice»\n",
    "- ✅ No hyperparameters to tune \n",
    "\n",
    "**Gaussian Naive Bayes**  \n",
    "- ✅ Works «quite well in many real-world situations» (makes it worth a try)\n",
    "- ✅ Can be extremely fast compared to more sophisticated methods (interesting)\n",
    "- 🤔 Requires only a small amount of training data (we have lots of data so interesting but not a substantial advantage)\n",
    "- 🤔 Known to be a bad *estimator*, outputs from `predict_proba` are not to be taken too seriously (problematic) \n",
    "\n",
    "**Support Vector Machines**  \n",
    "- ✅ Effective in high dimensional spaces (likely useful)\n",
    "- ✅ Memory efficient (important)\n",
    "- 🤔 SVMs do not directly provide probability estimates. This need an extra step in training and might increase compute substiantially.   \n",
    "\n",
    "**k-NearestNeighbor**\n",
    "- 🤔 Not memory efficient since all samples are stored (likely problematic) \n",
    "\n",
    "**RandomForest**\n",
    "- 🤔 Prone to overfit, careful hyperparameter tuning likely necessary\n",
    "\n",
    "**DNNs**\n",
    "- 🤔 Need lots of data (that we might not have)\n",
    "- 🤔 Training likely more compute intense than for «traditional» estimators\n",
    "- 😥 Fast inference possibly requires GPU. That possibly makes is harder/more expensive to productionize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**\n",
    "- Cleaning and preparing the data according to findings from EDA\n",
    "- Filter data to get balanced samples 50:50 women/men\n",
    "- Extract features with librosa/aubio: MFCCs, fundamental frequency FO\n",
    "- Standardize features (e.g. with scikit pipeline)\n",
    "- Reduce dimensions with PCA where helpful\n",
    "- Check for outliers in extracted features (e.g. from faulty recordings) and remove these\n",
    "\n",
    "**Get baseline**\n",
    "- Get baseline with DummyClassifier\n",
    "\n",
    "**Training/Tuning**\n",
    "- Find best features for chosen classifier(s) \n",
    "- Grid-search / random search best hyperparameters with cross-validation\n",
    "- Find best option for predicting on podcast data: e.g. predict on chunks of length n seconds, use a rolling window over audio etc.\n",
    "- Tackle challenges: Multiple speakers, speakers interrupting each other, dense conversation with many speaker changes, low quality recordings from protagonists that are being interviewed via smartphone, skype or on location with background noises, music, advertising, trailers\n",
    "\n",
    "**Evaluate models and compare results**\n",
    "- Compare results in regard to metric of accuracy\n",
    "- Discuss findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6) Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### References, links\n",
    "\n",
    "#### Fundamentals\n",
    "- [Voice frequency range](https://en.wikipedia.org/wiki/Voice_frequency)\n",
    "- [Human frequency range](https://blog.accusonus.com/pro-audio-production/human-voice-frequency-range/)\n",
    "- [Understanding voice production](https://voicefoundation.org/health-science/voice-disorders/anatomy-physiology-of-voice-production/understanding-voice-production/)\n",
    "- [The frequency range of the voice fundamental in the speech of male and female adults](https://www.researchgate.net/publication/240312210_The_frequency_range_of_the_voice_fundamental_in_the_speech_of_male_and_female_adults)\n",
    "- [How to create a genderless voice](https://www.youtube.com/watch?v=qH6KB7MrOPw)\n",
    "- [Language pitch](https://erikbern.com/2017/02/01/language-pitch.html)\n",
    "- [Individual differences in human voice pitch](https://royalsocietypublishing.org/doi/10.1098/rsos.191642)\n",
    "\n",
    "#### Gender equality in media\n",
    "- [Describing Gender Equality in French Audiovisual Streams with a Deep Learning Approach](https://www.viewjournal.eu/article/10.18146/2213-0969.2018.jethc156/)\n",
    "- [Ringier EqualVoice initiative to increase women's visibility in media coverage](https://www.ringier.com/en/equalvoice-initiative-increase-womens-visibility-media-coverage)\n",
    "- [Gender Balance Guide for Media](http://genderbalancecontent.womeninnews.org/)\n",
    "- [The Pudding – Film Dialogue from 2,000 screenplays, Broken Down by Gender and Age](https://pudding.cool/2017/03/film-dialogue/)\n",
    "- [What Do We Hear When Women Speak?](https://www.nytimes.com/2019/11/20/us/politics/women-voices-authority.html)\n",
    "- [Bashing Hillary Clinton’s voice](https://linguisticpulse.com/2016/02/08/bashing-hillary-clintons-voice-screeching-shrieking-and-shrill/)\n",
    "\n",
    "#### Podcast\n",
    "- [Podcast growth doubles every year](https://pex.com/blog/podcast-growth-doubles-every-year-over-7-million-hours-uploaded-in-2019/)\n",
    "\n",
    "#### Technical research, code and tools\n",
    "- [Introduction to Audio Classification with Deep Neural Networks](https://nbviewer.jupyter.org/github/IliaZenkov/sklearn-audio-classification/blob/master/sklearn_audio_classification.ipynb)\n",
    "- [Pitch-Tracking, or How to Estimate the Fundamental Frequency in Speech](https://medium.com/@neurodatalab/pitch-tracking-or-how-to-estimate-the-fundamental-frequency-in-speech-on-the-examples-of-praat-fe0ca50f61fd)\n",
    "- [How do you analyze the fundamental frequency of a PCM or WAV sample?](https://stackoverflow.com/questions/65268/how-do-you-analyse-the-fundamental-frequency-of-a-pcm-or-wav-sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
